{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Import Libraries\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas \n",
    "import csv\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "src='/home/shared_data/textmining_genderrecognition_topicextraction/dataset_text_mining_Reuters_RCV2/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# View dir dataset_text_mining_Reuters_RCV2/trc2\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_tec2=src+'trc2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src=path_tec2+'trc2.csv'\n",
    "# ps=pandas.read_csv(src, encoding='latin-1')\n",
    "# ps.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src2=path_tec2+'headlines-docs.csv'\n",
    "# ps2=pandas.read_csv(src2, encoding='latin-1')\n",
    "# ps2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #verifica quanti record sono diversi tra le due tabelle\n",
    "# x=ps==ps2\n",
    "# len(np.where(x['message']==False)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src3=path_tec2+'headlines.txt'\n",
    "# ps3=pandas.read_csv(src3, encoding='latin-1')\n",
    "# ps3.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src4=path_tec2+'headlines.csv'\n",
    "# ps4=pandas.read_csv(src4, encoding='latin-1')\n",
    "# ps4.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src5=path_tec2+'TRC2-headlines-docs-TRECBLOG.v2'\n",
    "# f = open(src5)     # This is a big file\n",
    "# stampa_righe=0\n",
    "# for line in f:                # Using 'for ... in' on file object\n",
    "#     if stampa_righe==4:\n",
    "#         break;\n",
    "#     print (line)                # ',' keeps print from adding a line break\n",
    "#     stampa_righe+=1\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# View files on dataset_text_mining_Reuters_RCV2/rcv1\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "def remove_tag(line,x,y):\n",
    "    ris=line[x:(len(line)-y)]\n",
    "    return ris\n",
    "\n",
    "def convert_xml_to_dataframe(src):\n",
    "    src_rcv=src\n",
    "    f = open(src_rcv)     \n",
    "    paragrafo=[]\n",
    "    code=[]\n",
    "    ris={}\n",
    "    \n",
    "    for line in f:                \n",
    "        if(line[:3]=='<p>'):\n",
    "            paragrafo.append(remove_tag(line,3,5))\n",
    "        if(line[:7]=='<title>'):\n",
    "            ris['title']=remove_tag(line,7,9)\n",
    "        if(line[:10]=='<headline>'):\n",
    "            ris['headline']=remove_tag(line,10,12)\n",
    "        if(line[:8]=='<byline>'):\n",
    "            ris['autore']=remove_tag(line,8,10)\n",
    "        if(line[:14]=='  <code code=\"'):\n",
    "            code.append(remove_tag(line,14,3))\n",
    "            \n",
    "    ris['code']=str(\",\".join(code))\n",
    "    ris['text']=str(\" \".join(paragrafo))\n",
    "    f.close()\n",
    "    ris_pd_xml=pandas.DataFrame([ris])\n",
    "    return ris_pd_xml\n",
    "\n",
    "def lista_file(src_dir):\n",
    "    list_dir=os.listdir(src_dir)\n",
    "    lista_file=[]\n",
    "    for dir in list_dir:\n",
    "        if( dir!='MD5SUMS' and dir!='dtds' and dir!='codes'):\n",
    "            file=os.listdir(src_dir+dir)\n",
    "            for f in file:\n",
    "                if(f!='.ipynb_checkpoints'):\n",
    "                    lista_file.append(dir+'/'+f)\n",
    "    return lista_file\n",
    "\n",
    "def build_df(src_dir,lista_file,rcv,indice_file='indice.txt',non_convertiti_file='file_non_convertiti.txt'):\n",
    "    df=convert_xml_to_dataframe(src_dir+lista_file[0])\n",
    "    i=1\n",
    "    checkpoint=src+rcv\n",
    "    indice_path= src+indice_file\n",
    "    non_convertiti_path= src+non_convertiti_file\n",
    "    non_convertiti=''\n",
    "    \n",
    "        \n",
    "    if not Path(non_convertiti_path).exists():\n",
    "        f= open(non_convertiti_path, \"w\")\n",
    "        f.close()\n",
    "    f=open(non_convertiti_path,\"r\")\n",
    "    if( f.readline()==''):\n",
    "        non_convertiti=''\n",
    "        f.close()\n",
    "    else:\n",
    "        f=open(non_convertiti_path,\"r\")\n",
    "        non_convertiti=str(f.read())\n",
    "        f.close()\n",
    "    \n",
    "        \n",
    "    if not Path(indice_path).exists():\n",
    "        f= open(indice_path, \"w\")\n",
    "        f.close()    \n",
    "    f=open(indice_path,\"r\")\n",
    "    if( f.readline()==''):\n",
    "        ind=1\n",
    "        f.close()\n",
    "    else:\n",
    "        f=open(indice_path,\"r\")\n",
    "        ind=int(f.read())\n",
    "        if Path(checkpoint).exists():\n",
    "            df=pandas.read_csv(checkpoint)\n",
    "        f.close()\n",
    "    \n",
    "    \n",
    "    i=ind\n",
    "    start =time.time()\n",
    "    salva_ogni=25000\n",
    "    for f in lista_file[ind:]:\n",
    "        if( i%salva_ogni==0 or i%(len(lista_file)-1)==0):\n",
    "            df.to_csv(checkpoint, index=False)\n",
    "            indice= open(indice_path, \"w\")\n",
    "            indice.truncate(0)\n",
    "            indice.write(str(i))\n",
    "            indice.close()\n",
    "            end = time.time()\n",
    "            t = time.strftime(\"%Hh:%Mm:%Ss\",time.gmtime(int(end)-int(start)))\n",
    "            print(\"elaborati\",i,\"file su\",len(lista_file),\",file corrotti:\",(len(non_convertiti.split(','))-1),\",la dim: del csv:\",\n",
    "                  len(df),\",tempo impiegato per trasformare\",salva_ogni,\"file: \"+t)\n",
    "            start =time.time()\n",
    "        i=i+1\n",
    "        try:\n",
    "            df2=convert_xml_to_dataframe(src_dir+f)    \n",
    "            df=df.append(df2, ignore_index=True)\n",
    "        except:\n",
    "            non_convertiti=non_convertiti+','+f\n",
    "            non_convertiti_l= open(non_convertiti_path, \"w\")\n",
    "            non_convertiti_l.truncate(0)\n",
    "            non_convertiti_l.write(str(non_convertiti))\n",
    "            non_convertiti_l.close()\n",
    "            print(\"file: \",non_convertiti_l)\n",
    "    return df\n",
    "\n",
    "def merge(ds1=\"rcv.csv\",ds2=\"rcv_parte2.csv\"):\n",
    "    path_file=src+ds1\n",
    "    df=pandas.read_csv(path_file)\n",
    "    print(\"Originale:\",len(df),'+')\n",
    "    path_file2=src+ds2\n",
    "    df2=pandas.read_csv(path_file2)\n",
    "    print(\"Nuovo:\",len(df2),'=')\n",
    "    df=df.append(df2,ignore_index=True)\n",
    "    print('----------------------')\n",
    "    df.to_csv(path_file, index=False)    \n",
    "    print('Risultato',len(df))\n",
    "    os.remove(path_file2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src_dir=src+'rcv1/'\n",
    "# lista_file=lista_file(src_dir)\n",
    "# print(\"Totale file: \",len(lista_file))\n",
    "# df=build_df(src_dir,lista_file,'rcv.csv')\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src_dir=src+'rcv1/'\n",
    "# lista_file=lista_file(src_dir)\n",
    "# print(\"Totale file: \",len(lista_file))\n",
    "# df=build_df(src_dir,lista_file,'rcv_parte2.csv')\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "806801\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>headline</th>\n",
       "      <th>autore</th>\n",
       "      <th>code</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UK: UK shares set for nervous week,upside seen...</td>\n",
       "      <td>UK shares set for nervous week,upside seen lim...</td>\n",
       "      <td>Dale Faulken</td>\n",
       "      <td>UK,M11,MCAT</td>\n",
       "      <td>The UK share market is unlikely to make much h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USA: CBOT wheat ends mostly lower on weather.</td>\n",
       "      <td>CBOT wheat ends mostly lower on weather.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA,M14,M141,MCAT</td>\n",
       "      <td>CBOT soft red winter wheat futures closed most...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  UK: UK shares set for nervous week,upside seen...   \n",
       "1      USA: CBOT wheat ends mostly lower on weather.   \n",
       "\n",
       "                                            headline        autore  \\\n",
       "0  UK shares set for nervous week,upside seen lim...  Dale Faulken   \n",
       "1           CBOT wheat ends mostly lower on weather.           NaN   \n",
       "\n",
       "                code                                               text  \n",
       "0        UK,M11,MCAT  The UK share market is unlikely to make much h...  \n",
       "1  USA,M14,M141,MCAT  CBOT soft red winter wheat futures closed most...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_file=src+\"rcv.csv\"\n",
    "if Path(src+\"rcv_parte2.csv\").exists():\n",
    "    merge()\n",
    "df=pandas.read_csv(path_file)\n",
    "print(len(df))\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Code extraction\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estrai codes\n",
    "def estrai_code(path,salta_,columns):\n",
    "    dir_code=path\n",
    "    f = open(dir_code)\n",
    "    code={}\n",
    "    salta=0\n",
    "    for line in f:                \n",
    "        if salta<salta_:\n",
    "            salta+=1\n",
    "        else:\n",
    "            l=line.split()\n",
    "            if(len(l)>0):\n",
    "                code[l[0]]=' '.join(l[1:])\n",
    "    f.close()\n",
    "    topic_code=pandas.DataFrame.from_dict(code,orient='index').reset_index()\n",
    "    topic_code.columns=columns\n",
    "    return topic_code\n",
    "\n",
    "path_c=src+'rcv1/codes/'\n",
    "industry_codes=estrai_code(path_c+'industry_codes.txt',2,['industry_code','description'])\n",
    "region_codes=estrai_code(path_c+'region_codes.txt',2,['region_code','description'])\n",
    "topic_codes=estrai_code(path_c+'topic_codes.txt',2,['topic_code','description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not Path(src+\"industry_codes.csv\").exists():\n",
    "    industry_codes.to_csv(src+\"industry_codes.csv\", index=False)\n",
    "if not Path(src+\"region_codes.csv\").exists():\n",
    "    region_codes.to_csv(src+\"region_codes.csv\", index=False)\n",
    "if not Path(src+\"topic_codes.csv\").exists():\n",
    "    topic_codes.to_csv(src+\"topic_codes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Extraction multilingual data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_xml_to_dataframe(src):\n",
    "    src_rcv=src\n",
    "    f = open(src_rcv)     \n",
    "    paragrafo=[]\n",
    "    code=[]\n",
    "    ris={}\n",
    "    \n",
    "    for line in f:                \n",
    "        if(line[:3]=='<p>'):\n",
    "            paragrafo.append(remove_tag(line,3,5))\n",
    "        if(line[:7]=='<title>'):\n",
    "            ris['title']=remove_tag(line,7,9)\n",
    "        if(line[:10]=='<headline>'):\n",
    "            ris['headline']=remove_tag(line,10,12)\n",
    "        if(line[:8]=='<byline>'):\n",
    "            ris['autore']=remove_tag(line,8,10)\n",
    "        if(line[:12]=='<code code=\"'):\n",
    "            code.append(remove_tag(line,12,3))\n",
    "            \n",
    "    ris['code']=str(\",\".join(code))\n",
    "    t=str(\" \".join(paragrafo))\n",
    "    ris['text']=t[:len(t)-7]\n",
    "    f.close()\n",
    "    ris_pd_xml=pandas.DataFrame([ris])\n",
    "    return ris_pd_xml\n",
    "\n",
    "def lista_file_multilingual_(src_dir):\n",
    "    list_dir=os.listdir(src_dir)\n",
    "    lista_file=[]\n",
    "    i=0\n",
    "    ind_split=[]\n",
    "    for dir in list_dir:\n",
    "        if(dir!='readme.txt' and dir!='MD5SUMS' and dir!='.ipynb_checkpoints'):\n",
    "            dir_multilingual=os.listdir(src_dir+dir)\n",
    "            ind_split.append(i)\n",
    "            print(i)\n",
    "            for dir_region in dir_multilingual:\n",
    "                if(dir_region!='.ipynb_checkpoints'):\n",
    "                    file=os.listdir(src_dir+dir+'/'+dir_region)\n",
    "                    for f in file:\n",
    "                        if(f!='.ipynb_checkpoints'):\n",
    "                            lista_file.append(dir+'/'+dir_region+'/'+f)\n",
    "                            i+=1\n",
    "    return lista_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src_dir_multilingual=src+'RCV2_Multilingual_Corpus/'\n",
    "# lista_file_multilingual=lista_file_multilingual_(src_dir_multilingual)\n",
    "# print(\"Totale file: \",len(lista_file_multilingual))\n",
    "# df_multilingual=build_df(src_dir_multilingual,lista_file_multilingual,'rcv_multilingual.csv',\n",
    "#     indice_file='indice_multilingual.txt',non_convertiti_file='file_non_convertiti_multilingual.txt')\n",
    "# df_multilingual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src_dir_multilingual=src+'RCV2_Multilingual_Corpus/'\n",
    "# lista_file_multilingual=lista_file_multilingual_(src_dir_multilingual)\n",
    "# print(\"Totale file: \",len(lista_file_multilingual))\n",
    "# df_multilingual=build_df(src_dir_multilingual,lista_file_multilingual,'rcv_multilingual_parte2.csv',\n",
    "#     indice_file='indice_multilingual.txt',non_convertiti_file='file_non_convertiti_multilingual.txt')\n",
    "# df_multilingual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "806801\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>headline</th>\n",
       "      <th>autore</th>\n",
       "      <th>code</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[台灣央行]標售50億台幣1個月期NCDs加權平均得標利率為6.385%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ASIAZ,DEVGCOZ,EASIAZ,TAIWAN,M13,MCAT</td>\n",
       "      <td>〔路透社台北24日電〕　　台灣央行週四午後標售50億台幣的1個月期可轉讓定期存單(NCDs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>美國經濟學家預期今年民間借款需求相當不錯</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NAMZ,USA,USAZ,USW,E12,ECAT</td>\n",
       "      <td>〔路透社紐約29日電〕　　美國著名經濟學家考夫曼表示,美國經濟成長強勁,加上短期利率僅會小...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   title                                headline  autore  \\\n",
       "0    NaN   [台灣央行]標售50億台幣1個月期NCDs加權平均得標利率為6.385%      NaN   \n",
       "1    NaN                   美國經濟學家預期今年民間借款需求相當不錯      NaN   \n",
       "\n",
       "                                   code  \\\n",
       "0  ASIAZ,DEVGCOZ,EASIAZ,TAIWAN,M13,MCAT   \n",
       "1            NAMZ,USA,USAZ,USW,E12,ECAT   \n",
       "\n",
       "                                                text  \n",
       "0   〔路透社台北24日電〕　　台灣央行週四午後標售50億台幣的1個月期可轉讓定期存單(NCDs...  \n",
       "1   〔路透社紐約29日電〕　　美國著名經濟學家考夫曼表示,美國經濟成長強勁,加上短期利率僅會小...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_file_multilingual=src+\"rcv_multilingual.csv\"\n",
    "if Path(src+\"rcv_multilingual_parte2.csv\").exists():\n",
    "    merge(ds1='rcv_multilingual.csv',ds2='rcv_multilingual_parte2.csv')\n",
    "df_multilingual=pandas.read_csv(path_file_multilingual)\n",
    "print(len(df))\n",
    "df_multilingual.head(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
